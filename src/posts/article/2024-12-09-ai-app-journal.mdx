---
layout: post
title:  "AI App development journal"
date:   2024-12-09
categories: AI
draft: true
---



## Apps

Over the past month I've started building apps with AI in a day that would have taken 5-10X longer before. The goal of this post is to capture my learnings. I'll try and summarize each app at the top, share an overview of the development process, and then a running log at the bottom.



1. **Goal Journal**
2. **PDF OCD**
3. **White Paper Podcast**
4. **Investor call viewer**



The goal behind **Goal Journal** was to design a mobile app for capturing my progress on various goals. There are plenty of progress trackers out there, but I wanted something that would let me tap a record button, describe what I had done, and then use AI to transcribe and summarize it.



My wife and I scan all of the documents that we receive so that they're easier to share and find later. This might be a bit OCD (hence the name), but we've found it's a simple hack for putting PDFs in our todo list.  The problem is that when you want to find a document from a year or two ago, most of the documents are not OCR'd and the filenames are terrible. **PDF OCD** runs hourly in the background and when it finds a new PDF it OCR's and uses AI to generate a new filename with the date, company, and description of the doc.



## Learnings



## Log



### December 9th - Theme button



### December 7th - reader mode

I asked Composer to create a **reader mode** button on my blog. There were three challenges. The first was learning how to hide the side panels. The second was learning how to position the button with the `reshaped` library. The third was learning how to make the layout interactive despite it being a server component. 

It took one nudge to get the layout the hide the side panels with the right API. It took a couple of nudges to learn how to use the `reshaped` library, but giving it access to the docs and running `tsc` fixded the issues. It took one nudge to get the interaction to work with RSC which was super impressive.





### December 5th - Consolidating transcripts

The transcripts app has logic for consolidating the timestamped segments so that the transcript is easier to read. There are a couple of rules here. First its good to try and have segments that are 30 to 60s long. Second, it's nice to create segments when the person mentions a slide like "going to a slide" since that's a logical place to start reading a new thought.

This logic has a suprising number of edge cases given that the transcript needs to be parsed. And as a result the agent kept failing. With **agent** mode enabled, I asked it to look at its own output and it was able to conclude it failed, but it was not able to fix it. I then asked it to write unit tests to exercise edge cases and add fine grained logging to look at the values. This approach was good, but even with agent mode which could run the tests, look at the terminal output, and then re-write the code it kept failing. 



This is the first logic oriented task i've seen it not be able to do.



The goal behind **PDF OCD**



